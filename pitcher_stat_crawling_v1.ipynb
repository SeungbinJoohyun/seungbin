{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선수 ID 지정 (예: 73330은 특정 선수의 고유 번호)\n",
    "player_id = \"11310\"\n",
    "url = f\"https://statiz.sporki.com/player/?m=year&p_no={player_id}\"\n",
    "# url ='https://statiz.sporki.com/stats/?m=team&m2=pitching'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_statiz_pitcher_data(url):\n",
    "    \"\"\"\n",
    "    스탯티즈에서 선발투수 등판 기록을 크롤링하는 함수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # HTTP 요청 헤더 설정 (봇 차단 방지)\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        # 웹페이지 요청\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # BeautifulSoup 객체 생성\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 테이블 찾기 (일반적으로 통계 데이터는 table 태그 안에 있음)\n",
    "        table = soup.find('table')\n",
    "        if not table:\n",
    "            print(\"테이블을 찾을 수 없습니다.\")\n",
    "            return None\n",
    "        \n",
    "        # 헤더 추출 (th 태그 또는 첫 번째 tr의 td 태그)\n",
    "        headers = []\n",
    "        header_row = table.find('tr')\n",
    "        if header_row:\n",
    "            header_cells = header_row.find_all(['th', 'td'])\n",
    "            headers = [cell.get_text(strip=True) for cell in header_cells]\n",
    "        \n",
    "        # 데이터 행 추출\n",
    "        data_rows = []\n",
    "        rows = table.find_all('tr')[1:]  # 첫 번째 행(헤더) 제외\n",
    "        \n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            if cells:  # td 태그가 있는 행만 처리\n",
    "                row_data = []\n",
    "                for cell in cells:\n",
    "                    # 셀 내용 추출 (줄바꿈 제거, 공백 정리)\n",
    "                    text = cell.get_text(separator=' ', strip=True)\n",
    "                    # 추가 줄바꿈 문자 제거\n",
    "                    text = text.replace('\\n', ' ').replace('\\r', '').strip()\n",
    "                    # 연속된 공백을 하나로 통일\n",
    "                    text = ' '.join(text.split())\n",
    "                    row_data.append(text)\n",
    "                \n",
    "                if row_data:  # 빈 행이 아닌 경우만 추가\n",
    "                    data_rows.append(row_data)\n",
    "        \n",
    "        return headers, data_rows\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"웹페이지 요청 중 오류 발생: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"데이터 추출 중 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picherdata=crawl_statiz_pitcher_data(url)\n",
    "picherdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picherdata_DF=pd.DataFrame(picherdata[1])\n",
    "picherdata_DF = picherdata_DF.set_axis(picherdata[0], axis=1)\n",
    "picherdata_DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picherdata_DF.iloc[-1]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
